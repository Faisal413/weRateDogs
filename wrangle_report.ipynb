{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e951e2af",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "The \"We Rate Dogs\" Twitter archive contains over 5000 tweets, which have been filtered to create the enhanced archive that forms the basis of this analysis. The goal of this project is to wrangle the data - gather, assess, and clean - into a tidy dataset, and then provide analyses and visualizations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80fcd465",
   "metadata": {},
   "source": [
    "# Project Steps Overview\n",
    "\n",
    "### Step 1: Gathering data\n",
    "\n",
    "### Step 2: Assessing data\n",
    "\n",
    "### Step 3: Cleaning data\n",
    "\n",
    "### Step 4: Storing data\n",
    "\n",
    "### Step 5: Analyzing, and visualizing data\n",
    "\n",
    "### Step 6: Reporting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bde8aa9",
   "metadata": {},
   "source": [
    "After I import all the important packges i needed i start with strp 1\n",
    "\n",
    "- ## Gathering data\n",
    "\n",
    "i gathered data from : \n",
    "\n",
    "    1.CSV files\n",
    "    2.programmatic download from website\n",
    "    3.Twitter API's JSON data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c1d2ce1",
   "metadata": {},
   "source": [
    "firstly , Enhanced Twitter Archive , then Tweet Image Predictions . also , Twitter API's JSON data. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e397e451",
   "metadata": {},
   "source": [
    "then i did the seconed step \n",
    "\n",
    "- ## Step 2: Assessing Data\n",
    "\n",
    "i  assessed the data in two ways : Visual assessment and Programmatic assessment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09c1e632",
   "metadata": {},
   "source": [
    "I had included more than 8 quality issues in twitter Archive which are : \n",
    "\n",
    "- #### Quality issues from Twitter Archive:Â¶\n",
    "    \n",
    "    1. this varibale should be an integers: in_reply_to_status_id, in_reply_to_user_id, retweeted_status_id, andretweeted_status_user_id .\n",
    "    2. Also, here we have missing data for colmuns in df_twitter_archive: in_reply_to_status_id, in_reply_to_user_id retweeted_status_id retweeted_status_user_id,retweeted_status_timestamp and expanded_urls.\n",
    "    3. Some tweets have no dog names (a, the) and might be a retweet.\n",
    "    4. The timestamp is present as an object, which is should be converted into datetime to be exploitable.\n",
    "    5. as we see in the dataframe df_twitter_archive the ( rating_numerator and rating_denominator ) are not accurate.\n",
    "    6. The dog types should have NaN instead of None .\n",
    "    7. some records have more than one dog stage .\n",
    "    8. there are dublacti values .\n",
    "    9. convert the Datatype of 'tweet_id' from integer to string.\n",
    "\n",
    "\n",
    "and 2 quality issues Image Predictions which are :\n",
    "\n",
    "- #### Quality issues from image_predictions:\n",
    "    1. column names are not clearly descriptive\n",
    "    2. Some jpgs are repeated.\n",
    "\n",
    "and one for Twitter API's JSON data. \n",
    "\n",
    "- #### over all Tidiness issues :\n",
    "    1.  One column instead of 4 columns in dog_stage column .... (doggo, floofer, pupper, puppo).\n",
    "    2. one dataset instead of many datasets.\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f74dd1b",
   "metadata": {},
   "source": [
    "## Step 3: Cleaning data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "260c77fd",
   "metadata": {},
   "source": [
    "I start with making one master dataframe for all the tables i have to easliy maniplate with data and make great wrangling and visualaisoin . then i take every qualty issue and fix it . and now we have better workspace to play with the data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1aca7839",
   "metadata": {},
   "source": [
    "and last and not least i end with step 4 before i analysed and viualise the data \n",
    "\n",
    "## Step 4: Storing data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de4cacc1",
   "metadata": {},
   "source": [
    "i stored the work in (twitter_archive_master.csv)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
